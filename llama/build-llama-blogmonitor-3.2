~/code/models/llama.cpp/llama-cli -c 12000  -m ~/code/models/Llama-3.2-3B-Instruct-Q6_K_L.gguf --prompt-cache context-llama-blogmonitor-3.2.gguf  -r "<|eot_id|>"  -f system_prompt_llama_blogmonitor_3.2  --temp 0  -sp  
