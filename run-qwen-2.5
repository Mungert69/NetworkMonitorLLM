~/code/models/llama.cpp/llama-cli -c 12000  -m ~/code/models/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-Q4_K_L.gguf --prompt-cache context-qwen-2.5.gguf --prompt-cache-ro -f system_prompt_qwen_2.5_run  -r "<|im_end|>"  --temp 0  -sp -if --color --simple-io -ctv q8_0 -ctk q8_0 -fa --in-suffix "<|im_end|>\n<|im_start|>assistant\n"
