~/code/models/llama.cpp/llama-cli -c 12000  -m ~/code/models/Llama-3.2-3B-Instruct-bf16-q8_0.gguf --prompt-cache context-llama-3.2-all.gguf  -r "<|eot_id|>"  -f system_prompt_llama_3.2_all -ub 2048 -b 2048  --temp 0  -sp --in-suffix "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"

