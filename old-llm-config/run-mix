~/code/models/llama.cpp/build/bin/main -c 4000 -n 4000  -m ~/code/models/mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf  --prompt-cache context-mix.gguf --prompt-cache-ro  -f initialPrompt.txt   -ins --keep -1 --temp 0
