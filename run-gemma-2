~/code/models/llama.cpp/llama-cli -c 12000  -m ~/code/models/Gemma-The-Writer-9B-D_AU-Q6_k.gguf --prompt-cache-ro  --prompt-cache context-gemma-2-blogmonitor.gguf  -r "<|end_of_turn|>"  -f system_prompt_gemma_2_blogmonitor_run -sp -if --keep -1 --temp 0 --color --simple-io -sp --in-suffix "<start_of_turn>model\n"
